{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just checking the amount of PD and control subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/Data/Datasets/Parkinson/radiological/PPMI/spect-mri/original\"\n",
    "clases = os.listdir(data_path)\n",
    "\n",
    "for clase in clases:\n",
    "    clase_path = os.path.join(data_path, clase, \"PPMI\")\n",
    "    subjects = os.listdir(clase_path)\n",
    "    print(\"clase: \", clase)\n",
    "    print(\"subjects: \", len(subjects))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the corresponding patients information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regarding particular patients of interest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_path = \"../../../../../../Datasets/Parkinson/radiological/PPMI/spect-mri/filtered\"\n",
    "splits = [\"test\", \"train\"]\n",
    "groups = [\"control\", \"parkinson\"]\n",
    "train_control_cases, train_parkinson_cases, test_control_cases, test_parkinson_cases = [], [], [], []\n",
    "\n",
    "for split in splits:\n",
    "    for group in groups:\n",
    "        cases = gen_path + \"/\" + split + \"/\" + group + \"/\" + \"parcellation/preprocessed/full_rois/mri_png\"\n",
    "\n",
    "        if group == \"control\" and split == \"train\":\n",
    "            train_control_cases = os.listdir(cases)\n",
    "        elif group == \"control\" and split == \"test\":\n",
    "            test_control_cases = os.listdir(cases)\n",
    "        elif group == \"parkinson\" and split == \"train\":\n",
    "            train_parkinson_cases = os.listdir(cases)\n",
    "        else:\n",
    "            test_parkinson_cases = os.listdir(cases)\n",
    "            \n",
    "train_control_cases = list(map(int, train_control_cases))\n",
    "test_control_cases = list(map(int, test_control_cases))\n",
    "train_parkinson_cases = list(map(int, train_parkinson_cases))\n",
    "test_parkinson_cases = list(map(int, test_parkinson_cases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"====== control ======\")\n",
    "print(train_control_cases)\n",
    "print(\"/n\")\n",
    "print(test_control_cases)\n",
    "print(\"====== parkinson ======\")\n",
    "print(train_parkinson_cases)\n",
    "print(\"/n\")\n",
    "print(test_parkinson_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_path = \"../../../../../../Datasets/Parkinson/radiological/PPMI/spect-mri/\"\n",
    "file_path = general_path  + \"MDS-UPDRS_Part_III_14Feb2024.csv\"\n",
    "updrs3_df = pd.read_csv(file_path)\n",
    "updrs3_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(updrs3_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UPDRS information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_path = \"../../../../../../Datasets/Parkinson/radiological/PPMI/spect-mri/\"\n",
    "\n",
    "print(\"UPDRS questionnarie PART I\")\n",
    "file_path1 = general_path  + \"MDS-UPDRS_Part_I_Patient_Questionnaire_29Jan2024.csv\"\n",
    "updrs1_df = pd.read_csv(file_path1)\n",
    "print(updrs1_df.columns)\n",
    "\n",
    "print(\"UPDRS questionnarie PART II\")\n",
    "file_path2 = general_path  + \"MDS_UPDRS_Part_II__Patient_Questionnaire_29Jan2024.csv\"\n",
    "updrs2_df = pd.read_csv(file_path2)\n",
    "print(updrs2_df.columns)\n",
    "\n",
    "print(\"UPDRS questionnarie PART IV\")\n",
    "file_path4 = general_path  + \"MDS-UPDRS_Part_IV__Motor_Complications_29Jan2024.csv\"\n",
    "updrs4_df = pd.read_csv(file_path4)\n",
    "print(updrs4_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patients information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_test_df = updrs3_df[updrs3_df[\"PATNO\"].isin(test_control_cases)]\n",
    "ctrl_train_df = updrs3_df[updrs3_df[\"PATNO\"].isin(train_control_cases)]\n",
    "pd_test_df = updrs3_df[updrs3_df[\"PATNO\"].isin(test_parkinson_cases)]\n",
    "pd_train_df = updrs3_df[updrs3_df[\"PATNO\"].isin(train_parkinson_cases)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UPDRS and H&Y scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ctrl_test_df = ctrl_test_df.groupby(\"PATNO\").count()\n",
    "filtered_ctrl_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ctrl_test_df[\"NHY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Angel estadio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(general_path + \"estadio.csv\")\n",
    "df.groupby(\"PATNO\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demografic info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"========== Train population ==========\")\n",
    "print(\"==== control: ====\")\n",
    "train_ctrl_age_mean = ctrl_train_df[\"ENROLL_AGE\"].mean()\n",
    "train_ctrl_age_std = ctrl_train_df[\"ENROLL_AGE\"].std()\n",
    "print(\"==== parkinson: ====\")\n",
    "train_pd_age_mean = pd_train_df[\"ENROLL_AGE\"].mean()\n",
    "train_pd_age_std = pd_train_df[\"ENROLL_AGE\"].std()\n",
    "\n",
    "print(\"control age: \", train_ctrl_age_mean, train_ctrl_age_std)\n",
    "print(\"parkinson age: \", train_pd_age_mean, train_pd_age_std)\n",
    "\n",
    "print(\"========== Test population ==========\")\n",
    "print(\"==== control: ====\")\n",
    "test_ctrl_age_mean = ctrl_test_df[\"ENROLL_AGE\"].mean()\n",
    "test_ctrl_age_std = ctrl_test_df[\"ENROLL_AGE\"].std()\n",
    "print(\"==== parkinson: ====\")\n",
    "test_pd_age_mean = pd_test_df[\"ENROLL_AGE\"].mean()\n",
    "test_pd_age_std = pd_test_df[\"ENROLL_AGE\"].std()\n",
    "\n",
    "print(\"control age: \", test_ctrl_age_mean, test_ctrl_age_std)\n",
    "print(\"parkinson age: \", test_pd_age_mean, test_pd_age_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook is for many brain parcellations translation purposes** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CycleGan data moving\n",
    "\n",
    "We have 58 subjects for the control and the parkinson groups, respectively. We want to train:\n",
    "* **========== experiment 1: ==========** \n",
    "* Control to parkinson translation\n",
    "* Domain A: control\n",
    "* Domain B: parkinson\n",
    "For the training of this net, we need (by experience) around 1800 frames by each domain. In this sense, each subject has 182 slices, so we will work in this dataframe interval:\n",
    "\n",
    "* low_rate = 91-15\n",
    "* up_rate = 91+15\n",
    "\n",
    "The above results in 1798 slices over each domain where each suject is represented by the 31 central slices\n",
    "\n",
    "* **========== experiment 2: ==========** \n",
    "* MRI to SPECT domain translation\n",
    "In this case we want to get 900 mri images for control and the same amount for parkinson subjects. So, as we have 58 subjects in each group, we must to have the following:\n",
    "\n",
    "900/58 = 16 images for mri control and parkinson, respectively. So, at the end we will have \n",
    "\n",
    "* Domain A and B (MRI, Spect, respectively): 928 mri and spect images for control and the same amount for parkinson in each domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the original embc cases\n",
    "root_path = \"/home/Data/Datasets/Parkinson/radiological/PPMI/spect-mri/filtered/\"\n",
    "original_embc_cases = root_path + \"train/parkinson/parcellation/preprocessed/full_rois/spect_png/\"\n",
    "embc_cases = sorted(os.listdir(original_embc_cases))\n",
    "print(\"amount of original cases: \", len(embc_cases))\n",
    "\n",
    "#getting all the pd cases \n",
    "extension_embc_cases = root_path + \"train/parkinson/extension/spect_png/\"\n",
    "augmented_cases = sorted(os.listdir(extension_embc_cases))\n",
    "print(\"amount of augmented_cases: \", len(augmented_cases))\n",
    "\n",
    "extra_cases = list(set(augmented_cases) - set(embc_cases))\n",
    "print(\"amount of extra cases: \", len(extra_cases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"train\"\n",
    "group = \"parkinson\"\n",
    "modality = \"spect_png\"\n",
    "experiment = \"full_rois\"\n",
    "technique = \"preprocessed\"\n",
    "\n",
    "source_path = \"../../../../../../Datasets/Parkinson/radiological/PPMI/spect-mri/filtered/\"\n",
    "current_root_path = os.path.join(source_path, split, group, \"parcellation\", technique, experiment, \"preprocessed2\", modality)\n",
    "cases = sorted(os.listdir(current_root_path))\n",
    "print(\"Number of cases: \", len(cases))\n",
    "\n",
    "\n",
    "if experiment == \"full_rois\":\n",
    "    save_path = \"../data/\" + technique + \"/\" + experiment + \"/mri_to_spect/preprocessed2/\" + split + \"_\" + modality.split(\"_\")[0]  \n",
    "else:\n",
    "    save_path = \"../data/\" + technique + \"/\" + experiment + \"/mri_to_spect/\" + split + \"_\" + modality.split(\"_\")[0] \n",
    "    \n",
    "print(\"Saving to: \", save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for case in embc_cases:\n",
    "    print(\"Case: \", case)\n",
    "    case_path = os.path.join(current_root_path, case)\n",
    "    files = sorted(os.listdir(case_path))\n",
    "    can_files = len(files)\n",
    "    print(\"Number of files: \", can_files)\n",
    "    \n",
    "    if modality == \"mri_png\":\n",
    "        half_frame = 145\n",
    "        low_rate = half_frame - 8\n",
    "        up_rate = half_frame + 8\n",
    "    else:\n",
    "        half_frame = 45\n",
    "        low_rate = half_frame - 10\n",
    "        up_rate = half_frame + 5\n",
    "        \n",
    "    \n",
    "    for file in files[low_rate-1:up_rate]:\n",
    "        file_path = os.path.join(case_path, file)\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)            \n",
    "        os.system(\"cp \" + file_path + \" \" + save_path) \n",
    "        \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier data setting\n",
    "In this part we will create the csv file for the T1 and spect modalities\n",
    "* **For T1 images:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#root_path = \"../../../../../../Datasets/Parkinson/radiological/PPMI/spect-mri/filtered/\"\n",
    "root_path = \"/home/Data/franklin/Doctorado/parkinson/projects/T1-SPECT-PD-translation/imgs_results/\"\n",
    "path = \"full_rois/preprocessed/mri_to_spect/prodromal_mri_filtered_slices/\"\n",
    "clases = os.listdir(os.path.join(root_path, path))\n",
    "print(len(clases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_csv2 = open(root_path + \"/raw_control_pd_MRI_fullRois_TRAIN.csv\", '+w')\n",
    "for clase in clases:\n",
    "    cases_path = os.path.join(root_path, split, clase, \"parcellation/raw\", experiment, modality)\n",
    "    cases = sorted(os.listdir(cases_path))\n",
    "    for case in cases:\n",
    "        case_path = os.path.join(cases_path, case)\n",
    "        images = sorted(os.listdir(case_path))\n",
    "        for image in images:\n",
    "            image_path = os.path.join(case_path, image)\n",
    "            col_name = ',' + clase + \"\\n\"\n",
    "            #print(image_path + col_name)\n",
    "            file_csv2.write(image_path + col_name)\n",
    "file_csv2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(root_path + \"/raw_control_pd_SPECT_fullRois_TEST.csv\", header=None)\n",
    "df.columns = [\"path\", \"label\"]\n",
    "df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For synthetic images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"../imgs_results/full_rois/preprocessed/mri_to_spect/mri_filtered_slices/\"\n",
    "#modality = \"test_mri\"\n",
    "\n",
    "#cases = os.listdir(root_path + modality)\n",
    "cases = os.listdir(root_path)\n",
    "\n",
    "#file_csv2 = open(root_path + modality + \"_fullRois.csv\", '+w')\n",
    "file_csv2 = open(root_path + \"mri_to_spect_filtered.csv\", '+w')\n",
    "for case in cases:\n",
    "    #case_path = os.path.join(root_path, modality, case)\n",
    "    case_path = os.path.join(root_path, case)\n",
    "    imgs = sorted(os.listdir(case_path))\n",
    "    for img in imgs:\n",
    "        image_path = os.path.join(case_path, img)\n",
    "        clase = img.split(\"_\")[0]\n",
    "        col_name = ',' + clase + \"\\n\"\n",
    "        #print(image_path+col_name)\n",
    "        file_csv2.write(image_path + col_name)\n",
    "file_csv2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Full train and test synthetic versions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "root_path = \"../imgs_results/full_rois/preprocessed/mri_to_spect/\"\n",
    "split = \"train\"\n",
    "folder_path = os.path.join(root_path, \"full_\"+split+\"_mri_png\")\n",
    "\n",
    "imgs = os.listdir(folder_path)\n",
    "\n",
    "file_csv2 = open(root_path + \"full_\"+split + \"_mriSpectFullRois.csv\", '+w')\n",
    "#print(root_path + \"full_\"+split + \"_fullRois.csv\")\n",
    "for img in imgs:\n",
    "    image_path = os.path.join(folder_path, img)\n",
    "    clase = img.split(\"_\")[0]\n",
    "    col_name = ',' + clase + \"\\n\"\n",
    "    #print(image_path+col_name)\n",
    "    file_csv2.write(image_path + col_name)\n",
    "file_csv2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(root_path + \"full_\"+split+ \"_mriSpectFullRois.csv\", header=None)\n",
    "df.columns = [\"path\", \"label\"]\n",
    "df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For prodromal subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "root_path = \"/home/Data/franklin/Doctorado/parkinson/projects/T1-SPECT-PD-translation/imgs_results/full_rois/preprocessed/mri_to_spect/\"\n",
    "split = \"prodromal_mri_filtered_slices\"\n",
    "current_path = os.path.join(root_path, split)\n",
    "cases = sorted(os.listdir(current_path))\n",
    "print(len(cases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_csv = open(root_path + \"/prodromal_synthetic_spect_fullRois_TRAIN.csv\", '+w')\n",
    "\n",
    "for case in cases:\n",
    "    #print(\"Case: \", case)\n",
    "    case_path = os.path.join(current_path, case)\n",
    "    #print(\"case_path: \", case_path)\n",
    "    images = sorted(os.listdir(case_path))\n",
    "    #print(len(images))\n",
    "    for image in images:\n",
    "        image_path = os.path.join(case_path, image)\n",
    "        col_name = ','+ \"prodromal\\n\"\n",
    "        #print(image_path + col_name)\n",
    "        file_csv.write(image_path + col_name)\n",
    "file_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(root_path + \"embc_extension/extension_prodromal_MRI_fullRois_TRAIN.csv\", header=None)\n",
    "df.columns = [\"path\", \"label\"]\n",
    "df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For SWEDD subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"../../../../../../Datasets/Parkinson/radiological/PPMI/spect-mri/filtered/\"\n",
    "split = \"swedd\"\n",
    "experiment = \"extension\"\n",
    "modality = \"spect_png\"#<----- change this to mri_png when needed\n",
    "cases = sorted(os.listdir(os.path.join(root_path, split, experiment, modality)))\n",
    "print(len(cases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_csv = open(root_path + \"/swedd_SPECT_preprocessed2_TEST.csv\", '+w')\n",
    "\n",
    "for case in cases:\n",
    "    case_path = os.path.join(root_path, split, experiment, modality, case)\n",
    "    images = sorted(os.listdir(case_path))\n",
    "    for image in images:\n",
    "        image_path = os.path.join(case_path, image)\n",
    "        col_name = ','+ \"swedd\\n\"\n",
    "        #print(image_path + col_name)\n",
    "        file_csv.write(image_path + col_name)\n",
    "file_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(root_path + \"/swedd_SPECT_preprocessed2_TEST.csv\", header=None)\n",
    "df.columns = [\"path\", \"label\"]\n",
    "df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **For cycleGan**\n",
    "#### Test_control mri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/preprocessed/full_rois/mri_to_spect/\"\n",
    "set = \"test\"\n",
    "group = \"mri\"#\"control\"\n",
    "\n",
    "images = os.listdir(path + set + \"_\" + group)\n",
    "\n",
    "file_csv2 = open(path + set + \"_\" + group + \".csv\", '+w')\n",
    "for image in images:\n",
    "    image_path = os.path.join(path, set + \"_\" + group, image)\n",
    "    clase = image.split(\"_\")[0]\n",
    "    col_name = ',' + clase + \"\\n\"\n",
    "    #print(image_path+col_name)\n",
    "    file_csv2.write(image_path + col_name)\n",
    "file_csv2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MRI filtered slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../imgs_results/full_rois/mri_to_spect/mri_filtered_slices/\"\n",
    "groups = os.listdir(path)\n",
    "\n",
    "file_csv2 = open(path + \"mri_filtered_slices.csv\", '+w')\n",
    "for group in groups:\n",
    "    \n",
    "    images = os.listdir(path + group)\n",
    "    \n",
    "    for image in images:\n",
    "        image_path = os.path.join(path, group, image)\n",
    "        clase = image.split(\"_\")[0]\n",
    "        col_name = ',' + clase + \"\\n\"\n",
    "        file_csv2.write(image_path + col_name)\n",
    "file_csv2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(path + \"mri_filtered_slices.csv\", header=None)\n",
    "df.columns = [\"path\", \"label\"]\n",
    "df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving preprocessed files \n",
    "The aim of this section is move all the preprocessing steps into a folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"../../../../../../Datasets/Parkinson/radiological/PPMI/spect-mri/filtered\"\n",
    "split = \"test\"\n",
    "group = \"control\"\n",
    "modality = \"mri\"\n",
    "current_root_path = os.path.join(root_path, split, group, modality)\n",
    "cases = sorted(os.listdir(current_root_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for case in cases[:2]:\n",
    "    preprocessed_path = os.path.join(current_root_path, case, \"preprocessed\")\n",
    "    files = sorted(os.listdir(preprocessed_path))\n",
    "    nii_files = [file for file in files if file.endswith(\".nii\")]\n",
    "    print(\"nii files: \", nii_files)\n",
    "    print(\"amount of nii: \", len(nii_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Until here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the csv file for preprocessed SPECT files in version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/home/Data/Datasets/Parkinson/radiological/PPMI/spect-mri/filtered/\"\n",
    "split = \"train\"\n",
    "groups = [\"control\", \"parkinson\"]\n",
    "file_csv2 = open(root_path + \"pdControlSpectPreprocessed2TRAIN.csv\", '+w')\n",
    "\n",
    "for group in groups:\n",
    "    cases_path = os.path.join(root_path, split, group, \"parcellation/raw/full_rois/spect_png/\")\n",
    "    cases = os.listdir(cases_path)\n",
    "    for case in cases:\n",
    "        case_path = os.path.join(cases_path, case)\n",
    "        images = os.listdir(case_path)\n",
    "        for image in images:\n",
    "            image_path = os.path.join(case_path, image)\n",
    "            col_name = ',' + group + \"\\n\"\n",
    "            #print(image_path + col_name)\n",
    "            file_csv2.write(image_path + col_name)\n",
    "\n",
    "file_csv2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Know the PD distribution regarding the H&Y scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From here for Prodromal and SWEDD subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/home/Data/Datasets/Parkinson/radiological/PPMI/spect-mri/filtered\"\n",
    "csv_file = root_path + \"/sweddStagesEmbcExtension.csv\"\n",
    "extra_df = pd.read_csv(csv_file)\n",
    "extra_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the patient ID and corresponding H&Y scale as txt file for each split\n",
    "columns = [\"Pat_id\", \"H & Y Stage\"]\n",
    "extra_df[columns].to_csv(root_path + \"/sweddStages.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Until here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_csv_file = \"/home/Data/Datasets/Parkinson/radiological/PPMI/spect-mri/filtered/embcBaselinev2.csv\"\n",
    "extended_csv = \"/home/Data/Datasets/Parkinson/radiological/PPMI/spect-mri/filtered/embcExtensionv2.csv\"\n",
    "\n",
    "bases_line_df = pd.read_csv(baseline_csv_file)\n",
    "extended_df = pd.read_csv(extended_csv)\n",
    "print(\"len of base: \", len(bases_line_df))\n",
    "print(\"len extended: \", len(extended_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From here we get the extra PD subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_patients = bases_line_df[\"Pat_id\"].unique()\n",
    "#getting patients that no are in the base\n",
    "extended_patients_df = extended_df[~extended_df[\"Pat_id\"].isin(base_patients)]\n",
    "print(\"len extended: \", len(extended_patients_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Until here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bases_line_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_patients_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split regarding the H&Y scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(extended_patients_df[\"H & Y Stage\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the train/test sets for the base line approach regarding the H&Y scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_1 = bases_line_df[bases_line_df[\"H & Y Stage\"]==1.0]\n",
    "stage_2 = bases_line_df[bases_line_df[\"H & Y Stage\"]==2.0]\n",
    "stage_3 = bases_line_df[bases_line_df[\"H & Y Stage\"]==3.0]\n",
    "stage_4 = bases_line_df[bases_line_df[\"H & Y Stage\"]==4.0]\n",
    "stage_5 = bases_line_df[bases_line_df[\"H & Y Stage\"]==5.0]\n",
    "\n",
    "print(\"on stage 1: \", len(stage_1))\n",
    "print(\"on stage 2: \", len(stage_2))\n",
    "print(\"on stage 3: \", len(stage_3))\n",
    "print(\"on stage 4: \", len(stage_4))\n",
    "print(\"on stage 5: \", len(stage_5))\n",
    "print(\"total: \", len(stage_1)+len(stage_2)+len(stage_3)+len(stage_4)+len(stage_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"on stage 1: \", len(stage_1)*0.8)\n",
    "print(\"on stage 2: \", len(stage_2)*0.8)\n",
    "print(\"on stage 3: \", len(stage_3)*0.8)\n",
    "print(\"on stage 4: \", len(stage_4)*0.8)\n",
    "print(\"on stage 5: \", len(stage_5)*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#due to the 80/20 for the train/test setting, we have to ensure the proper PD distribution regarding the H&Y scale:\n",
    "8 + 47 + 1 + 2 #---> for 1 to 4 H&Y rating scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing randomly some PD subjects for train/test sets\n",
    "random_seed = 14\n",
    "\n",
    "stg_1_sample = 8\n",
    "stg_2_sample = 47\n",
    "stg_3_sample = 1\n",
    "stg_4_sample = 2\n",
    "#stg_5_sample = 1\n",
    "\n",
    "#for train\n",
    "stg_1_train = stage_1.sample(stg_1_sample, random_state=random_seed)\n",
    "stg_2_train = stage_2.sample(stg_2_sample, random_state=random_seed)\n",
    "stg_3_train = stage_3.sample(stg_3_sample, random_state=random_seed)\n",
    "stg_4_train = stage_4.sample(stg_4_sample, random_state=random_seed)\n",
    "\n",
    "stg_1_patients_train = list(stg_1_train[\"Pat_id\"].values)\n",
    "stg_2_patients_train = list(stg_2_train[\"Pat_id\"].values)\n",
    "stg_3_patients_train = list(stg_3_train[\"Pat_id\"].values)\n",
    "stg_4_patients_train = list(stg_4_train[\"Pat_id\"].values)\n",
    "\n",
    "train_df = pd.concat([stg_1_train, stg_2_train, stg_3_train, stg_4_train])\n",
    "print(\"for train: \", len(train_df))\n",
    "\n",
    "#for test\n",
    "stg_1_test = stage_1[~stage_1[\"Pat_id\"].isin(stg_1_patients_train)]\n",
    "stg_2_test = stage_2[~stage_2[\"Pat_id\"].isin(stg_2_patients_train)]\n",
    "stg_3_test = stage_3[~stage_3[\"Pat_id\"].isin(stg_3_patients_train)]\n",
    "stg_4_test = stage_4[~stage_4[\"Pat_id\"].isin(stg_4_patients_train)]\n",
    "\n",
    "stg_1_patients_test = list(stg_1_test[\"Pat_id\"].values)\n",
    "stg_2_patients_test = list(stg_2_test[\"Pat_id\"].values)\n",
    "stg_3_patients_test = list(stg_3_test[\"Pat_id\"].values)\n",
    "stg_4_patients_test = list(stg_4_test[\"Pat_id\"].values)\n",
    "\n",
    "test_df = pd.concat([stg_1_test, stg_2_test, stg_3_test, stg_4_test])\n",
    "print(\"for train: \", len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cases = train_df[\"Pat_id\"].values\n",
    "test_cases = test_df[\"Pat_id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Creating the txt files** \n",
    "* For both train/test in the EMBC baseline approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the patient ID and corresponding H&Y scale as txt file for each split\n",
    "columns = [\"Pat_id\", \"H & Y Stage\"]\n",
    "train_df[columns].to_csv(\"trainPdStagesV2.txt\", sep=\"\\t\", index=False)\n",
    "test_df[columns].to_csv(\"testPdStagesV2.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From extended version only get the original embc cases**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For the additional PD subjects in the EMBC extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_path = '/home/Data/Datasets/Parkinson/radiological/PPMI/spect-mri/filtered/' \n",
    "csv_train = os.path.join(gen_path + 'pdControlSpectPreprocessed2TRAIN.csv')\n",
    "csv_test = os.path.join(gen_path + 'pdControlSpectPreprocessed2TEST.csv')\n",
    "\n",
    "extended_train_df, extended_test_df = pd.read_csv(csv_train), pd.read_csv(csv_test)\n",
    "columns = [\"path\", \"label\"]\n",
    "extended_train_df.columns = columns\n",
    "extended_test_df.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the original embc cases\n",
    "root_path = \"/home/Data/Datasets/Parkinson/radiological/PPMI/spect-mri/filtered/\"\n",
    "original_embc_cases = root_path + \"train/parkinson/parcellation/preprocessed/full_rois/spect_png/\"\n",
    "embc_cases = sorted(os.listdir(original_embc_cases))\n",
    "print(\"amount of original cases: \", len(embc_cases))\n",
    "\n",
    "#getting all the pd cases \n",
    "extension_embc_cases = root_path + \"train/parkinson/extension/spect_png/\"\n",
    "augmented_cases = sorted(os.listdir(extension_embc_cases))\n",
    "print(\"amount of augmented_cases: \", len(augmented_cases))\n",
    "\n",
    "extra_cases = list(set(augmented_cases) - set(embc_cases))\n",
    "print(\"amount of extra cases: \", len(extra_cases))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting the dataframe for only the extended patientes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_1 = extended_patients_df[\"Pat_id\"].unique()\n",
    "print(len(extra_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Until here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the patient ID and corresponding H&Y scale as txt file for each split\n",
    "gen_path = \"/home/Data/Datasets/Parkinson/radiological/PPMI/spect-mri/filtered/\"\n",
    "columns = [\"Pat_id\", \"H & Y Stage\"]\n",
    "extended_patients_df[columns].to_csv(gen_path+\"extensionPdStagesTest.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the new train/test sets and move to the save folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/home/Data/Datasets/Parkinson/radiological/PPMI/spect-mri/filtered\"\n",
    "save_path = root_path + \"/stratifying_stages/\"\n",
    "\n",
    "sets = [\"test\", \"train\"]\n",
    "modalities = [\"mri_png\", \"spect_png\"]\n",
    "\n",
    "total_cases = \"train_cases\"\n",
    "\n",
    "if total_cases == \"test_cases\":\n",
    "    print(\"over test cases\")\n",
    "    total_cases = test_cases\n",
    "    split = \"test\"\n",
    "else:\n",
    "    print(\"over train cases\")\n",
    "    total_cases = train_cases\n",
    "    split = \"train\"\n",
    "\n",
    "for case in total_cases:\n",
    "    print(\"case: \", case)\n",
    "    \n",
    "    for modality in modalities:\n",
    "        print(\"modality: \", modality) \n",
    "        modality_path1 = root_path + \"/\" + \"train\" + \"/parkinson/parcellation/raw/full_rois/\" + modality + \"/\" + str(case)\n",
    "        modality_path2 = root_path + \"/\" + \"test\" + \"/parkinson/parcellation/raw/full_rois/\" + modality + \"/\" + str(case)\n",
    "        if os.path.exists(modality_path1):\n",
    "            current_modality_path = modality_path1\n",
    "        if os.path.exists(modality_path2):\n",
    "            current_modality_path = modality_path2\n",
    "            \n",
    "        cases = sorted(os.listdir(current_modality_path))\n",
    "        print(\"case: \", case)\n",
    "        source_path = current_modality_path\n",
    "        current_save_path = save_path + split + \"/parkinson/\" + modality + \"/\" + str(case)\n",
    "        print(\"copying from: \", source_path)\n",
    "        print(\"to: \", current_save_path)  \n",
    "        shutil.copytree(source_path, current_save_path)     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/home/Data/Datasets/Parkinson/radiological/PPMI/spect-mri/filtered/stratifying_stages\"\n",
    "split = \"train\"\n",
    "groups = [\"control\", \"parkinson\"]\n",
    "modality = \"spect_png\"\n",
    "\n",
    "file_csv2 = open(root_path + \"/pdControlSpectTRAIN.csv\", '+w')\n",
    "\n",
    "for group in groups:\n",
    "    print(\"group: \", group)\n",
    "    if group == \"control\":\n",
    "        modality_path = os.path.join(root_path, split, group, \"parcellation/raw/full_rois/\", modality)\n",
    "        cases = os.listdir(modality_path)   \n",
    "    else:\n",
    "        modality_path = os.path.join(root_path, split, group, modality)\n",
    "        cases = sorted(os.listdir(modality_path))\n",
    "        \n",
    "    for case in cases:\n",
    "        case_path = os.path.join(modality_path, case)\n",
    "        images = sorted(os.listdir(case_path))\n",
    "        for image in images:\n",
    "            image_path = os.path.join(case_path, image)\n",
    "            col_name = ',' + group + \"\\n\"\n",
    "            print(image_path + col_name)\n",
    "            file_csv2.write(image_path + col_name)\n",
    "            \n",
    "file_csv2.close()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the csv file for the paper baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/Data/Datasets/Parkinson/radiological/spect_paper\"\n",
    "split = \"all_2d_val\"\n",
    "groups = [\"HC\", \"PD\"]\n",
    "\n",
    "file_csv2 = open(path + \"/pdControlSpectTEST.csv\", '+w')\n",
    "\n",
    "for group in groups:\n",
    "    print(\"group: \", group)\n",
    "    group_path = path + \"/\" + split + \"/\" + group\n",
    "    images =   os.listdir(group_path)\n",
    "    for image in images:\n",
    "        img_path = group_path + \"/\" + image\n",
    "        col_name = ',' + group + \"\\n\"\n",
    "        #print(img_path + col_name)\n",
    "        file_csv2.write(img_path + col_name)\n",
    "            \n",
    "file_csv2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unzip MRI-DTI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_path = \"/home/Data/Datasets/Parkinson/radiological/PPMI/mri-dti/original/pd_mri_dti\"\n",
    "files = os.listdir(gen_path)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unzip all the files\n",
    "for file in tqdm(files):\n",
    "    file_path = gen_path + \"/\" + file\n",
    "    with ZipFile(file_path, mode='r') as zip_ref:\n",
    "        zip_ref.extractall(gen_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
