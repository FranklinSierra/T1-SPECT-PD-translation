{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Loading trained networks**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = \"/home/Data/franklin/Doctorado/parkinson/projects/parcellation_translation/models/classifier/mri_spect/preprocessed/only_mri/Vgg16MRI.h5\"\n",
    "model = tf.keras.models.load_model(path_model, compile=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = model.get_layer(name='dropout_2')\n",
    "emb = Model(model.input, l1.output)\n",
    "emb.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting and saving the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the synthetic data\n",
    "split = \"test\"\n",
    "\n",
    "#synthetic_data = \"../imgs_results/full_rois/preprocessed/mri_to_spect/\"    \n",
    "gen_path = \"../../../../../../Datasets/Parkinson/radiological/PPMI/spect-mri/filtered/\"\n",
    "\n",
    "csv_train = os.path.join(gen_path + 'control_pd_MRI_fullRois_TRAIN.csv')\n",
    "csv_test = os.path.join(gen_path + 'control_pd_MRI_fullRois_TEST.csv')\n",
    "train_df = pd.read_csv(csv_train, header=None)\n",
    "train_df.columns = ['path', 'label']\n",
    "test_df = pd.read_csv(csv_test, header=None)\n",
    "test_df.columns = ['path', 'label']\n",
    "\n",
    "\n",
    "print(train_df.groupby('label').count())\n",
    "print(test_df.groupby('label').count())\n",
    "\n",
    "train_df[['case_number', 'slice_number']] = train_df['path'].str.extract(r'_case_(\\d+)_slice_(\\d+).png').astype(int)\n",
    "train_df_v2 = train_df[(train_df['slice_number'] > 41) & (train_df['slice_number'] < 132)]\n",
    "train_df_v2.drop('slice_number', axis=1, inplace=True)\n",
    "train_df_v2.drop('case_number', axis=1, inplace=True)\n",
    "\n",
    "#test\n",
    "test_df[['case_number', 'slice_number']] = test_df['path'].str.extract(r'_case_(\\d+)_slice_(\\d+).png').astype(int)\n",
    "test_df_v2 = test_df[(test_df['slice_number'] > 41) & (test_df['slice_number'] < 132)]\n",
    "test_df_v2.drop('slice_number', axis=1, inplace=True)\n",
    "test_df_v2.drop('case_number', axis=1, inplace=True)\n",
    "\n",
    "print(\"lengh of train: {}, lengh of test: {}\".format(len(train_df_v2), len(test_df_v2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ctrl = train_df_v2[train_df_v2['label'] == \"control\"]\n",
    "train_pd = train_df_v2[train_df_v2['label'] == \"parkinson\"]\n",
    "\n",
    "test_ctrl = test_df_v2[test_df_v2['label'] == \"control\"]\n",
    "test_pd = test_df_v2[test_df_v2['label'] == \"parkinson\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_v2.iloc[0]['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting embeddings for train and test\n",
    "\n",
    "label, pred = [], []    \n",
    "df = train_ctrl\n",
    "\n",
    "for i in range(len(df)):\n",
    "    img = tf.keras.preprocessing.image.load_img(df.iloc[i]['path'], target_size=(256, 256))\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img = img/255.0\n",
    "    img = tf.expand_dims(img, axis=0)\n",
    "    emb_test = emb.predict(img)\n",
    "    pred.extend(emb_test)\n",
    "    label.append(df.iloc[i]['label'])\n",
    "\n",
    "#pred = np.squeeze(pred, axis=1)\n",
    "pred = np.array(pred)\n",
    "print(\"dimension of predic: \", pred.shape)\n",
    "\n",
    "#label = np.squeeze(label, axis=1)\n",
    "label = np.array(label)\n",
    "print(\"dimension of label: \", label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the numpy arrays\n",
    "gen_path = \"/home/Data/franklin/Doctorado/parkinson/projects/parcellation_translation/embeddings/classifier/preprocessed/mri/\"\n",
    "\n",
    "if df.equals(test_ctrl):\n",
    "    np.save(gen_path + \"test_control/controlEmbTest.npy\", pred)\n",
    "    np.save(gen_path + \"test_control/controlLabTest.npy\", label)\n",
    "elif df.equals(test_pd):\n",
    "    np.save(gen_path + \"test_pd/parkinsonEmbTest.npy\", pred)\n",
    "    np.save(gen_path + \"test_pd/parkinsonLabTest.npy\", label)\n",
    "elif df.equals(train_ctrl):\n",
    "    np.save(gen_path + \"train_control/controlEmbTrain.npy\", pred)\n",
    "    np.save(gen_path + \"train_control/controlLabTrain.npy\", label)\n",
    "else:\n",
    "    np.save(gen_path + \"train_pd/parkinsonEmbTrain.npy\", pred)\n",
    "    np.save(gen_path + \"train_pd/parkinsonLabTrain.npy\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#haciendo dataframe\n",
    "df = pd.DataFrame(list(zip(label, pred)), columns=['clase', 'predicción'])\n",
    "df.groupby('clase').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimention reduction using Tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components = 2, init = 'pca')\n",
    "P1_tsne = tsne.fit_transform(pred)\n",
    "print(P1_tsne.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = P1_tsne[:,0]\n",
    "l2 = P1_tsne[:,1]\n",
    "\n",
    "df = df.drop(columns='predicción')\n",
    "df['x'] = l1\n",
    "df['y'] = l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (df['clase'] == 'CuNi1'),\n",
    "    (df['clase'] == 'CuNi2'),\n",
    "    (df['clase'] == 'CuNi3')\n",
    "    ]\n",
    "\n",
    "values = [1, 2, 3]\n",
    "\n",
    "df['labels'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Center of mass and distance between classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clases = ['CuNi1', 'CuNi2', 'CuNi3']\n",
    "full_x_com = []\n",
    "full_y_com = []\n",
    "for clase in clases:\n",
    "    df_clase = df[df['clase']== clase]\n",
    "    #center of mass x and y axes\n",
    "    x_com = df_clase['x'].sum()/len(df_clase)    \n",
    "    y_com = df_clase['y'].sum()/len(df_clase) \n",
    "    full_x_com.append(x_com)\n",
    "    full_y_com.append(y_com)\n",
    "    \n",
    "#print(\"====== about intra classes distances ========\")\n",
    "cuni1_cuni2_dis = np.sqrt(np.power(full_x_com[0]-full_x_com[1],2)+ np.power(full_y_com[0]-full_y_com[1],2))\n",
    "cuni1_cuni3_dis = np.sqrt(np.power(full_x_com[0]-full_x_com[2],2)+ np.power(full_y_com[0]-full_y_com[2],2))\n",
    "cuni2_cuni3_dis = np.sqrt(np.power(full_x_com[1]-full_x_com[2],2)+ np.power(full_y_com[1]-full_y_com[2],2))\n",
    "#print(\"====== about inter classes distances ========\")\n",
    "x_cuni1_mean = df[df['clase']=='CuNi1']['x'].mean()\n",
    "y_cuni1_mean = df[df['clase']=='CuNi1']['y'].mean()\n",
    "x_cuni2_mean = df[df['clase']=='CuNi2']['x'].mean()\n",
    "y_cuni2_mean = df[df['clase']=='CuNi2']['y'].mean()\n",
    "x_cuni3_mean = df[df['clase']=='CuNi3']['x'].mean()\n",
    "y_cuni3_mean = df[df['clase']=='CuNi3']['y'].mean()\n",
    "cuni1_dis = np.sqrt(np.power(full_x_com[0]-x_cuni1_mean,2)+ np.power(full_y_com[0]-y_cuni1_mean,2))\n",
    "cuni2_dis = np.sqrt(np.power(full_x_com[1]-x_cuni2_mean,2)+ np.power(full_y_com[1]-y_cuni2_mean,2))\n",
    "cuni3_dis = np.sqrt(np.power(full_x_com[2]-x_cuni3_mean,2)+ np.power(full_y_com[2]-y_cuni3_mean,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"============ ABOUT CENTER OF MASS ==============\")\n",
    "print('el centro de masa para CuNi1 es: x {} and y {}'.format(full_x_com[0], full_y_com[0]))\n",
    "print(\"el centro de masa para CuNi2 es: x {} and y {}\".format(full_x_com[1], full_y_com[1]))\n",
    "print(\"el centro de masa para CuNi3 es: x {} and y {}\".format(full_x_com[2], full_y_com[2]))\n",
    "print(\"============ ABOUT INTRA CLASS DISTANCES ==============\")\n",
    "print(\"la distancia CuNi1-CuNi2 es: {}\".format(cuni1_cuni2_dis))\n",
    "print(\"la distancia CuNi1-CuNi3 es: {}\".format(cuni1_cuni3_dis))\n",
    "print(\"la distancia CuNi2-CuNi3 es: {}\".format(cuni2_cuni3_dis))\n",
    "print(\"============ ABOUT INTER CLASS DISTANCES ==============\")\n",
    "print(\"la distancia CuNi1-CuNi1 es: {}\".format(cuni1_dis))\n",
    "print(\"la distancia CuNi2-CuNi2 es: {}\".format(cuni2_dis))\n",
    "print(\"la distancia CuNi3-CuNi3 es: {}\".format(cuni3_dis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "colors = {'CuNi1':'red', 'CuNi2':'green', 'CuNi3':'blue'}\n",
    "\n",
    "grouped = df.groupby('clase')\n",
    "for key, group in grouped:\n",
    "    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
    "\n",
    "ax.scatter([full_x_com[0]], [full_y_com[0]], color='black', s=250)\n",
    "ax.scatter([full_x_com[1]], [full_y_com[1]], color='yellow', s=250)\n",
    "ax.scatter([full_x_com[2]], [full_y_com[2]], color='orange', s=250)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
