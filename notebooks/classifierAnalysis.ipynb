{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to analyze the classifier performance over each PD subject regarding the H&Y rating scale.The idea here is get a boxplot over each PD subject in the test set setting the y-axis as the classifier Parkinson output prediction score and the x-axis will be the H&Y puntuation over each PD ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebooks referencia:\n",
    "1. https://colab.research.google.com/drive/1lOzcGOdi0JA3DGCMZS8vUDH0Y2QTub1-#scrollTo=c6cb21cd\n",
    "2. https://colab.research.google.com/drive/1T3CmzBZFXVQd7saXVqW9sQiPRP-BtFLO#scrollTo=e47292ba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, ConfusionMatrixDisplay \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input,Dense,GlobalAveragePooling2D,Flatten,concatenate,BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow import keras\n",
    "import imageio\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras import regularizers\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "from tqdm import tqdm\n",
    "from numpy import asarray\n",
    "import random\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import math\n",
    "import csv\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Helper functions**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframes(task):\n",
    "    \"\"\"\n",
    "    Loads data from three CSV files (training, validation, and test) into pandas DataFrames.\n",
    "\n",
    "    Returns:\n",
    "    train_df (pandas.DataFrame): DataFrame containing the training data with two columns, 'path' and 'label'.\n",
    "    val_df (pandas.DataFrame): DataFrame containing the validation data with two columns, 'path' and 'label'.\n",
    "    test_df (pandas.DataFrame): DataFrame containing the test data with two columns, 'path' and 'label'.\n",
    "    \"\"\"\n",
    "    # Set the path for the CSV files\n",
    "    print(\"working on task: \", task)\n",
    "    \n",
    "    gen_path = '/home/Data/Datasets/Parkinson/radiological/PPMI/spect-mri/filtered/' \n",
    "    #gen_path = '../../../../../../Datasets/Parkinson/radiological/PPMI/spect-mri/filtered/'\n",
    "    #synthetic_data = \"../imgs_results/full_rois/preprocessed/mri_to_spect/\"\n",
    "    paper_data = \"/home/Data/Datasets/Parkinson/radiological/spect_paper/\"\n",
    "    \n",
    "    if task == \"orginal_embc\":\n",
    "        print(\"working on orginal_embc\")\n",
    "        csv_train = os.path.join(gen_path + 'stratifying_stages/pdControlSpectTRAIN.csv')\n",
    "        csv_test = os.path.join(gen_path + 'stratifying_stages/pdControlSpectTEST.csv')\n",
    "        # csv_train = os.path.join(gen_path + 'embc_csvFiles/raw_control_pd_SPECT_fullRois_TRAIN.csv')\n",
    "        # csv_test = os.path.join(gen_path + 'embc_csvFiles/raw_control_pd_SPECT_fullRois_TEST.csv')\n",
    "    elif task == \"extension_embc\":\n",
    "        csv_train = os.path.join(gen_path + 'pdControlSpectPreprocessed2TRAIN.csv')\n",
    "        csv_test = os.path.join(gen_path + 'pdControlSpectPreprocessed2TEST.csv')\n",
    "    elif task == \"swedd\":\n",
    "        csv_test = os.path.join(gen_path + 'swedd_SPECT_preprocessed2_TEST.csv')\n",
    "    else:\n",
    "        csv_train = os.path.join(paper_data + 'pdControlSpectTRAIN.csv')\n",
    "        csv_test = os.path.join(paper_data + 'pdControlSpectTEST.csv')\n",
    "        \n",
    "    \n",
    "    if task != \"swedd\":\n",
    "        print(\"reading from : \", csv_train)\n",
    "        train_df = pd.read_csv(csv_train, header=None)\n",
    "        train_df.columns = ['path', 'label']\n",
    "\n",
    "        print(\"reading from : \", csv_test)\n",
    "        test_df = pd.read_csv(csv_test, header=None)\n",
    "        test_df.columns = ['path', 'label']\n",
    "        \n",
    "        return train_df, test_df\n",
    "\n",
    "    else:\n",
    "        print(\"reading from : \", csv_test)\n",
    "        test_df = pd.read_csv(csv_test, header=None)\n",
    "        test_df.columns = ['path', 'label']\n",
    "        \n",
    "        return test_df\n",
    "        \n",
    "    \n",
    "    #========= here for valid set from train set =========\n",
    "    \n",
    "    # X = train_df['path']\n",
    "    # y = train_df['label']\n",
    "\n",
    "    # # Split the training data into training and validation sets (90-10 split ratio)\n",
    "    # X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=14)\n",
    "\n",
    "    # # Concatenate the training data and their labels to create the training DataFrame\n",
    "    # train_df = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "    # # Concatenate the validation data and their labels to create the validation DataFrame\n",
    "    # val_df = pd.concat([X_val, y_val], axis=1)\n",
    "    \n",
    "    #========= until here =========   \n",
    "\n",
    "    # Return the DataFrames containing the loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_rescale(img):\n",
    "#     return (img / 127.5) - 1.0\n",
    "                                 \n",
    "def make_generator(df_test, HEIGHT, WIDTH, batch_size):\n",
    "    \n",
    "    test_datagen=ImageDataGenerator(rescale=1./255)#ImageDataGenerator(preprocessing_function=custom_rescale)\n",
    "    \n",
    "    test_generator=test_datagen.flow_from_dataframe(directory=None,\n",
    "                                                    dataframe=df_test,\n",
    "                                                    x_col='path',\n",
    "                                                    y_col='label',\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    seed=42,\n",
    "                                                    shuffle=False,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    target_size=(HEIGHT,WIDTH))\n",
    "\n",
    "    return test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    model = keras.models.load_model(model_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(label, stage, subject_id, modelo, test_df):\n",
    "    \n",
    "    batch = len(test_df)\n",
    "    test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "    #Obtiene el n√∫mero de frames.\n",
    "    number_of_frames = test_df.Frame\n",
    "    test_generator=test_datagen.flow_from_dataframe(dataframe=test_df,\n",
    "                                                  directory=None,\n",
    "                                                  x_col=\"path\",\n",
    "                                                  y_col=\"label\",\n",
    "                                                  batch_size=1,\n",
    "                                                  seed=42,\n",
    "                                                  shuffle=False,\n",
    "                                                  class_mode=\"categorical\",\n",
    "                                                  target_size=(256, 256))\n",
    "    pred = modelo.predict_generator(test_generator, steps = batch, verbose=1)\n",
    "    for k in range(len(pred)):\n",
    "        pred_k = pred[k]\n",
    "        writer.writerow([label, stage, subject_id, number_of_frames.iloc[k], pred_k[0], pred_k[1]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_testing_dataframe(test_df):\n",
    "    test_df = test_df.sort_values(by='path')\n",
    "    test_df['Frame'] = (\n",
    "         test_df.apply(lambda x: int(x.path.split('/')[-1].split('_')[-1][:-4]), axis=1)\n",
    "         )\n",
    "    \n",
    "    test_df['Patient'] = (\n",
    "         test_df.apply(lambda x: int(x.path.split('/')[-1].split('_')[-3]), axis=1)\n",
    "         )\n",
    "    \n",
    "    return test_df.sort_values(by='Frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_df(df):\n",
    "        \n",
    "    scan_info = []\n",
    "    pred = []\n",
    "    for i in range(len(df)):\n",
    "        clase = df.iloc[i]['GT']\n",
    "        \n",
    "        if clase == \"control\":\n",
    "            clase = \"C\"\n",
    "        else:\n",
    "            clase = \"P\"\n",
    "            \n",
    "        id = df.iloc[i]['PatId']\n",
    "        stage = df.iloc[i]['H&Y']\n",
    "        \n",
    "        to_save = clase + '_' + str(id) + '_' + str(stage)\n",
    "        scan_info.append(to_save)\n",
    "        \n",
    "    scan_set = set(scan_info)\n",
    "    scan_set = list(scan_set)\n",
    "    \n",
    "   \n",
    "    for i in range(len(df)):\n",
    "        pd_p = df.iloc[i]['Pd_prob']\n",
    "        ctrl_p = df.iloc[i]['Ctrl_prob']\n",
    "\n",
    "        if pd_p > ctrl_p:\n",
    "            pred.append(0)\n",
    "        else:\n",
    "            pred.append(1)\n",
    "\n",
    "    \n",
    "    df['Pred'] = pred    \n",
    "    df['Short_info'] = scan_info \n",
    "    \n",
    "    return df, scan_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_probs(df, group):\n",
    "    # Create a single plot\n",
    "    fig, ax = plt.subplots(figsize=(30, 10))\n",
    "\n",
    "    # Box plot\n",
    "    sns.boxplot(data=df,\n",
    "            x=\"H&Y\",       # x axis column from data\n",
    "            y=\"Pd_prob\",          # y axis column from data\n",
    "            width=0.8,            # The width of the boxes\n",
    "            color=\"skyblue\",      # Box colour\n",
    "            linewidth=2,          # Thickness of the box lines\n",
    "            showfliers=False,     # Stop showing the fliers\n",
    "            ax=ax)                # Assigning the plot to ax\n",
    "\n",
    "    # Strip plot\n",
    "    sns.stripplot(data=df,\n",
    "                x=\"H&Y\",      # x axis column from data\n",
    "                y=\"Pd_prob\",         # y axis column from data\n",
    "                color=\"crimson\",     # Colours the dots\n",
    "                linewidth=1,         # Dot outline width\n",
    "                alpha=0.4,           # Makes them transparent\n",
    "                ax=ax)               # Assigning the plot to ax\n",
    "    \n",
    "    # Add a horizontal dotted line at y=0.5\n",
    "    ax.axhline(y=0.5, color='red', linestyle='--', linewidth=1)\n",
    "\n",
    "    # Set title and labels for the plot\n",
    "    ax.set_title(\"Classifier performance \", fontsize=16)\n",
    "    ax.set_xlabel(\"H&Y\", fontsize=14)\n",
    "    ax.set_ylabel(\"% Pd_prob\", fontsize=14)\n",
    "    ax.tick_params(axis='x', which='both', length=0)  # Remove x-axis ticks and labels\n",
    "\n",
    "    # Remove vertical gridlines\n",
    "    ax.grid(axis='y', color='gray', linestyle=':', linewidth=0.5)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    \n",
    "    # save the plot as PDF file\n",
    "    if group == \"control\":\n",
    "        plt.savefig(\"control_plot.pdf\", format='pdf')\n",
    "    else:\n",
    "        plt.savefig(\"pd_plot.pdf\", format='pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Main**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "task=\"swedd\"\n",
    "\n",
    "if task != \"swedd\":\n",
    "    train_df, test_df = load_dataframes(task=task)\n",
    "    print(train_df.groupby('label').count())\n",
    "    print(test_df.groupby('label').count())\n",
    "else:\n",
    "    test_df = load_dataframes(task=task)\n",
    "    print(test_df.groupby('label').count())  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the embc baseLine patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_csv_file = \"/home/Data/Datasets/Parkinson/radiological/PPMI/spect-mri/filtered/embcBaselinev2.csv\"\n",
    "bases_line_df = pd.read_csv(baseline_csv_file)\n",
    "base_patients = bases_line_df[\"Pat_id\"].unique()\n",
    "# Convert list to string\n",
    "ids_to_exclude = [str(id) for id in base_patients]\n",
    "pattern = '|'.join(ids_to_exclude)\n",
    "\n",
    "#getting patients that no are in the base for train and test sets\n",
    "extended_patients_train_df = train_df[~train_df[\"path\"].str.contains(pattern)]\n",
    "extended_patients_test_df = test_df[~test_df[\"path\"].str.contains(pattern)]\n",
    "\n",
    "print(\"amount in train set: \", len(extended_patients_train_df))\n",
    "print(\"amount in test set: \", len(extended_patients_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = extended_patients_train_df\n",
    "test_df = extended_patients_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Until here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting by case number and slice number for the following situations:\n",
    "#preprocessing: from 41 to 132\n",
    "#raw cases: 109 to 180 or 109 to 127----> it needs to be checked\n",
    "# SPECT with preprocessed2: from 35 to 50\n",
    "\n",
    "#sorting by case number and slice number\n",
    "if task!= \"swedd\":\n",
    "    #train\n",
    "    train_df[['case_number', 'slice_number']] = train_df['path'].str.extract(r'_case_(\\d+)_slice_(\\d+).png').astype(int)\n",
    "    train_df_v2 = train_df[(train_df['slice_number'] > 35) & (train_df['slice_number'] < 50)]\n",
    "    train_df_v2.drop('slice_number', axis=1, inplace=True)\n",
    "    train_df_v2.drop('case_number', axis=1, inplace=True)\n",
    "\n",
    "    #test\n",
    "    test_df[['case_number', 'slice_number']] = test_df['path'].str.extract(r'_case_(\\d+)_slice_(\\d+).png').astype(int)\n",
    "    test_df_v2 = test_df[(test_df['slice_number'] > 35) & (test_df['slice_number'] < 50)]\n",
    "    test_df_v2.drop('slice_number', axis=1, inplace=True)\n",
    "    test_df_v2.drop('case_number', axis=1, inplace=True)\n",
    "    \n",
    "    print(\"lengh of train: {}, lengh of test: {}\".format(len(train_df_v2), len(test_df_v2)))\n",
    "else:\n",
    "    #test\n",
    "    test_df[['case_number', 'slice_number']] = test_df['path'].str.extract(r'_case_(\\d+)_slice_(\\d+).png').astype(int)\n",
    "    test_df_v2 = test_df[(test_df['slice_number'] > 35) & (test_df['slice_number'] < 50)]\n",
    "    test_df_v2.drop('slice_number', axis=1, inplace=True)\n",
    "    test_df_v2.drop('case_number', axis=1, inplace=True)\n",
    "    \n",
    "    print(\"lengh of test: {}\".format(len(test_df_v2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From here is for take the PD extra subjects in the extended version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curent_df = train_df_v2[train_df_v2['label'] == \"parkinson\"]\n",
    "curent_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Until here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sort_testing_dataframe(test_df_v2)#(curent_df)\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the H&Y stage \n",
    "#txt_file = \"/home/Data/Datasets/Parkinson/radiological/PPMI/spect-mri/filtered/stratifying_stages/testPdStages.txt\"\n",
    "if task == \"swedd\":\n",
    "    txt_file = \"/home/Data/Datasets/Parkinson/radiological/PPMI/spect-mri/filtered/sweddStages.txt\"\n",
    "else:\n",
    "    txt_file = \"/home/Data/Datasets/Parkinson/radiological/PPMI/spect-mri/filtered/extensionPdStagesTest.txt\"\n",
    "\n",
    "# Initialize an empty dictionary\n",
    "pat_stage_dict = {}\n",
    "\n",
    "# Open the file using the with statement\n",
    "with open(txt_file, 'r') as file:\n",
    "    # Iterate over each line in the file with its line number\n",
    "    for index, line in enumerate(file):\n",
    "        # Skip the first line\n",
    "        if index == 0:\n",
    "            continue\n",
    "        # Split the line into id and value based on whitespace\n",
    "        id, value = line.strip().split()\n",
    "        # Add the id and value to the dictionary, converting them to the appropriate types\n",
    "        pat_stage_dict[int(id)] = float(value)\n",
    "\n",
    "# Print the resulting dictionary\n",
    "print(pat_stage_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"H&Y\"] = df[\"Patient\"].map(pat_stage_dict).fillna(0)\n",
    "subjects = df[\"Patient\"].unique()\n",
    "print(subjects)\n",
    "print(len(subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"model loading... \")\n",
    "name = \"MobileNet\"\n",
    "model_path = '../models/embc/classifier/mri_spect_stratified/raw/' + name + '.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "save_path = '/home/Data/franklin/Doctorado/parkinson/projects/T1-SPECT-PD-translation/imgs_results/full_rois/raw/'\n",
    "to_write = save_path + 'sweddExtensionSubjectsPreds.csv'\n",
    "\n",
    "with open( to_write, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for subject in subjects:\n",
    "        print(subject)\n",
    "        single_df = df[df['Patient']==subject]\n",
    "        single_df = sort_testing_dataframe(single_df)\n",
    "        label = single_df['label'].iloc[0]\n",
    "        stage = single_df['H&Y'].iloc[0]\n",
    "        predict(label, stage, subject, model, single_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the csv predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_path = \"/home/Data/franklin/Doctorado/parkinson/projects/T1-SPECT-PD-translation/imgs_results/full_rois/raw/sweddExtensionSubjectsPreds.csv\"\n",
    "mobilenet_preds_df = pd.read_csv(preds_path)\n",
    "mobilenet_preds_df.columns = [\"GT\", \"H&Y\", \"PatId\", \"Frame\", \"Ctrl_prob\", \"Pd_prob\"]\n",
    "mobilenet_df, scan_info = custom_df(mobilenet_preds_df)\n",
    "mobilenet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(scan_info))\n",
    "print(len(scan_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting boxplots for Parkinson and Control populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting pd and control subdataframes\n",
    "ctrl_df = mobilenet_df[mobilenet_df[\"GT\"]==\"control\"]\n",
    "pd_df = mobilenet_df[mobilenet_df[\"GT\"]==\"parkinson\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_probs(ctrl_df, \"control\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_probs(pd_df, \"parkinson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting boxplots for SWEED and Prodromal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_probs(mobilenet_df, \"swedd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
