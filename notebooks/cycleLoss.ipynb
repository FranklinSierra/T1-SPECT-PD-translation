{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allows to import generator and discriminator\n",
    "!pip install -q git+https://github.com/tensorflow/examples.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "from os import listdir\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from numpy import vstack\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#AUTOTUNE = tf.data.AUTOTUNE\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "from PIL import Image\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 1\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "LAMBDA = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Useful methods**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all images in a directory into memory\n",
    "def load_images(path, size=(256,256)):\n",
    "    data_list = list()\n",
    "    #enumerate filenames in directory, assume all are images\n",
    "    for filename in listdir(path):\n",
    "        # load and resize the image\n",
    "        pixels = load_img(path + filename, target_size=size)\n",
    "        # convert to numpy array\n",
    "        pixels = img_to_array(pixels)\n",
    "        # store\n",
    "        data_list.append(pixels)\n",
    "    return asarray(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data augmentation techniques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(image):\n",
    "    cropped_image = tf.image.random_crop(image, size=[IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "# scaling the images to [-1, 1]\n",
    "def normalize(image):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image / 127.5) - 1\n",
    "    return image\n",
    "\n",
    "def random_jitter(image):\n",
    "    # resizing to 286 x 286 x 3\n",
    "    image = tf.image.resize(image, [286, 286],\n",
    "                          method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    # randomly cropping to 256 x 256 x 3\n",
    "    image = random_crop(image)\n",
    "\n",
    "    # random mirroring\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocess splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_train(image):\n",
    "    image = random_jitter(image)\n",
    "    image = normalize(image)\n",
    "    return image\n",
    "\n",
    "def preprocess_image_test(image):\n",
    "    image = normalize(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import and reuse the Pix2Pix models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "generator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "\n",
    "discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\n",
    "discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initializing optimizers, generator and discriminators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Loading models**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"../models/cyclegan/preprocessed/mri_to_spect/\"\n",
    "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
    "                           generator_f=generator_f,\n",
    "                           discriminator_x=discriminator_x,\n",
    "                           discriminator_y=discriminator_y,\n",
    "                           generator_g_optimizer=generator_g_optimizer,\n",
    "                           generator_f_optimizer=generator_f_optimizer,\n",
    "                           discriminator_x_optimizer=discriminator_x_optimizer,\n",
    "                           discriminator_y_optimizer=discriminator_y_optimizer)\n",
    "                           #nbi_cls_model=nbi_cls_model)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')\n",
    "ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    print(\"Restored from {}\".format(ckpt_manager.latest_checkpoint))\n",
    "else:\n",
    "    print(\"Initializing from scratch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Predicting over full test subjects**</font>\n",
    "## Main\n",
    "### Original CycleGan data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_path = '../../../../../../Datasets/Parkinson/radiological/PPMI/spect-mri/filtered/' \n",
    "csv_test = os.path.join(gen_path + 'control_pd_SPECT_fullRois_TRAIN.csv')\n",
    "mri_test_df = pd.read_csv(csv_test, sep=',', header=None)\n",
    "mri_test_df.columns = [\"path\", \"label\"]\n",
    "\n",
    "mri_test_df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "mri_test_df[['case_number', 'slice_number']] = mri_test_df['path'].str.extract(r'_case_(\\d+)_slice_(\\d+).png').astype(int)\n",
    "mri_test_df_v2 = mri_test_df[(mri_test_df['slice_number'] > 41) & (mri_test_df['slice_number'] < 132)]\n",
    "mri_test_df_v2.drop('slice_number', axis=1, inplace=True)\n",
    "mri_test_df_v2.drop('case_number', axis=1, inplace=True)\n",
    "\n",
    "print(\"len mri_tset_df_v2: \", len(mri_test_df_v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_df = mri_test_df_v2[mri_test_df_v2['label'] == \"control\"]\n",
    "parkinson_df = mri_test_df_v2[mri_test_df_v2['label'] == \"parkinson\"]\n",
    "\n",
    "print(len(control_df))\n",
    "print(len(parkinson_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cycle consistency loss\n",
    "\n",
    "$$ X \\rightarrow G(X) \\rightarrow F(G(X)) \\sim \\hat{X} $$\n",
    "\n",
    "In this case \n",
    "* $X:$ T1-MRI\n",
    "* $G(X):$ dopaminergic estimation from T1-MRI\n",
    "* $F(G(X)):$ reverse process to get T1-MRI from the dopaminergic estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cycle_loss(real_image, cycled_image):\n",
    "  loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
    "  return LAMBDA * loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subjects(df):\n",
    "    cases = []\n",
    "    for i in range(len(df)):\n",
    "        general_inf = df.iloc[i]['path']\n",
    "        img_name = general_inf.split(\"/\")[-1]\n",
    "        case = img_name.split(\"_\")[2]\n",
    "        cases.append(case)\n",
    "\n",
    "    unique_cases = set(cases)\n",
    "    unique_cases = list(unique_cases)\n",
    "    return unique_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_control_cases = get_subjects(control_df)\n",
    "unique_pd_cases = get_subjects(parkinson_df)\n",
    "\n",
    "print(\"len unique_control_cases: \", len(unique_control_cases))\n",
    "print(\"len unique_pd_cases: \", len(unique_pd_cases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subjects_errors(df, unique_cases):\n",
    "    size = (IMG_WIDTH, IMG_WIDTH)\n",
    "    subjects, errors_ind, errors_avg  = [], [], []\n",
    "    \n",
    "    for i in range(len(unique_cases)):\n",
    "        \n",
    "        #getting the filtered dataframe regarding the unique case\n",
    "        filtered_df = df[df['path'].str.contains(unique_cases[i])]\n",
    "        subjects.append(unique_cases[i])\n",
    "        \n",
    "        for j in range(len(filtered_df)):\n",
    "                  \n",
    "            data_list = list()\n",
    "            \n",
    "            path = filtered_df.iloc[j]['path']  \n",
    "            # # load and resize the image\n",
    "            pixels = load_img(path, target_size=size, color_mode= \"rgb\")\n",
    "            # convert to numpy array\n",
    "            pixels = img_to_array(pixels)\n",
    "            \n",
    "            data_list.append(pixels)\n",
    "            img_array = asarray(data_list)\n",
    "\n",
    "            split_ds = tf.data.Dataset.from_tensor_slices(img_array)\n",
    "            split_ds = split_ds.map(preprocess_image_test, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE)\n",
    "\n",
    "            real_x_img = next(iter(split_ds))\n",
    "            fake_y = generator_g.predict(real_x_img, verbose=0)\n",
    "            #fake_y = generator_g(real_x_img, training=False)\n",
    "            cycled_x = generator_f.predict(fake_y, verbose=0)\n",
    "            \n",
    "            total_cycle_loss = calc_cycle_loss(real_x_img, cycled_x)\n",
    "            #print(\"total_cycle_loss: \", total_cycle_loss.numpy())            \n",
    "            errors_ind.append(total_cycle_loss.numpy())\n",
    "        \n",
    "        avg_error = np.mean(errors_ind)\n",
    "        errors_avg.append(avg_error)\n",
    "        \n",
    "    return subjects, errors_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_pat, control_error_avg = get_subjects_errors(control_df, unique_control_cases)\n",
    "pd_pat, pd_error_avg = get_subjects_errors(parkinson_df, unique_pd_cases)\n",
    "\n",
    "print(\"len control_pat: \", len(control_pat))\n",
    "print(\"len control_error: \", len(control_error_avg))\n",
    "print(\"len pd_pat: \", len(pd_pat))\n",
    "print(\"len pd_error: \", len(pd_error_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [0] * len(control_pat) + [1] * len(pd_pat)\n",
    "ecm = control_error_avg + pd_error_avg\n",
    "\n",
    "print(\"len y_true: \", len(y_true))\n",
    "print(\"len ecm: \", len(ecm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.arange(0, len(control_pat))\n",
    "ids = ids.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting both lines\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(ids, control_error_avg, marker='o', linestyle='-', color='b', label='Avg error Control')\n",
    "plt.plot(ids, pd_error_avg, marker='s', linestyle='--', color='r', label='Avg error PD')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Subject ID')\n",
    "plt.ylabel('Cycle Loss')\n",
    "plt.title('Control against PD')\n",
    "\n",
    "# Adding legend\n",
    "plt.legend()\n",
    "\n",
    "# Displaying the plot\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplot and violin plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boxplots using Seaborn\n",
    "sns.boxplot(data=[control_error_avg, pd_error_avg])\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Error Value')\n",
    "plt.title('Boxplots of Cycle loss values')\n",
    "\n",
    "# Customize x-axis labels\n",
    "plt.xticks([0, 1], ['Control Error Values', 'PD Error Values'])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create violin plots using Seaborn\n",
    "sns.violinplot(data=[control_error_avg, pd_error_avg])\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Error Value')\n",
    "plt.title('Violin Plots of Cycle loss values')\n",
    "\n",
    "# Customize x-axis labels\n",
    "plt.xticks([0, 1], ['Control Error Values', 'PD Error Values'])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision and recall curves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, ecm)\n",
    "\n",
    "# Plot Precision-Recall curve against thresholds\n",
    "plt.plot(thresholds, precision[:-1], label='Precision')\n",
    "plt.plot(thresholds, recall[:-1], label='Recall')\n",
    "\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Precision/Recall')\n",
    "plt.title('Precision and Recall vs. Threshold Curve TEST set')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
